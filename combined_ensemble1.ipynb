{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/amitobe/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /Users/amitobe/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages (from nltk) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitobe/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "flair_model = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "def process_flair(dialogue):   # returning the flair score\n",
    "    sentence = flair.data.Sentence(dialogue)\n",
    "    flair_model.predict(sentence)\n",
    "    label = sentence.labels[0].value\n",
    "    score = sentence.labels[0].score\n",
    "    if label == 'POSITIVE':\n",
    "        return score\n",
    "    elif label == 'NEGATIVE':\n",
    "        return -score\n",
    "\n",
    "\n",
    "\n",
    "def return_sentiment(txt):  # returning single-sentence BERT score\n",
    "    encoded_input = tokenizer(txt, return_tensors='pt',padding=True,truncation=True)\n",
    "    output = bert_model(**encoded_input)\n",
    "    score = output[0][0].detach().numpy() \n",
    "    scores = softmax(score)\n",
    "    if np.argsort(scores)[2] == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (np.argsort(scores)[2]-1)*scores[np.argsort(scores)[2]]\n",
    "    \n",
    "def tb_score(txt):\n",
    "    sen = TextBlob(txt)\n",
    "    return pd.Series({'tb': sen.sentiment.polarity})\n",
    "\n",
    "def cal_vader_textblob_bert_flair(txt):\n",
    "    tb_score = TextBlob(txt).sentiment.polarity\n",
    "    obj = SentimentIntensityAnalyzer()\n",
    "    vader_score = obj.polarity_scores(txt)['compound']\n",
    "    flair_score = process_flair(txt)\n",
    "    bert_score = return_sentiment(txt)\n",
    "    #prob = logmodel3.predict_proba([[tb_score,vader_score,flair_score,bert_score]])[0]      \n",
    "    return np.array([[vader_score, tb_score,bert_score,flair_score]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for a function\n",
    "class FunctionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.func(X)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model (replace 'trained_model.pkl' with your model file)\n",
    "conversational_lr_loaded_model = joblib.load('conversational_lr_sav_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_lr_loaded_model.predict([[-0.8256    , -0.65      , -0.83824599, -0.99770665]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction pipeline with custom preprocessing and model\n",
    "prediction_pipeline = Pipeline([\n",
    "    ('custom_function', FunctionTransformer(func=cal_vader_textblob_bert_flair)),  # Custom preprocessing step\n",
    "    #('scaler', StandardScaler()),  # Standard scaling (for new data)\n",
    "   ('model', conversational_lr_loaded_model )  # Trained model (loaded)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_final = [\n",
    "    \"This bad thing should never have happened like this, its quite sad\",\n",
    "    \"Me too.\",\n",
    "    \"What am I?\",\n",
    "    \"I'm whatever\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5256    , -0.65      , -0.83824599, -0.99770665]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_vader_textblob_bert_flair(\"I am very sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [-1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the pipeline\n",
    "predictions = prediction_pipeline.predict(new_df_final[0])\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions:\", predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This bad thing should never have happened like this, its quite sad',\n",
       " 'Me too.',\n",
       " 'What am I?',\n",
       " \"I'm whatever\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 {color: black;background-color: white;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 pre{padding: 0;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-toggleable {background-color: white;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-item {z-index: 1;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-parallel-item:only-child::after {width: 0;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-476edf1d-14c5-4a5c-a3fb-bba085957dc1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom_function&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function cal_vader_textblob_bert_flair at 0x7ff2a8ac93b0&gt;)),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a62ba0ac-8e6f-440e-bd7f-2ffa28ee7431\" type=\"checkbox\" ><label for=\"a62ba0ac-8e6f-440e-bd7f-2ffa28ee7431\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom_function&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function cal_vader_textblob_bert_flair at 0x7ff2a8ac93b0&gt;)),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d9eabda7-3720-440f-8faa-ac7a5de80e93\" type=\"checkbox\" ><label for=\"d9eabda7-3720-440f-8faa-ac7a5de80e93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function cal_vader_textblob_bert_flair at 0x7ff2a8ac93b0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7ee2a033-4190-46ca-a35b-3d4f0025e725\" type=\"checkbox\" ><label for=\"7ee2a033-4190-46ca-a35b-3d4f0025e725\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('custom_function',\n",
       "                 FunctionTransformer(func=<function cal_vader_textblob_bert_flair at 0x7ff2a8ac93b0>)),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
